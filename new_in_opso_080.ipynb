{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdb13bf8-a849-42d4-af1b-599a34d44803",
   "metadata": {},
   "source": [
    "# Features and API changes in OpenSoundscape 0.8.0\n",
    "\n",
    "With examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1e670b-d7db-49a7-9150-748e4b72ed50",
   "metadata": {},
   "source": [
    "## Top-level imports\n",
    "\n",
    "We can now import some of the most frequently used classes at the top level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "51979297-b801-418f-b464-7f4d64c6e73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opensoundscape import Audio, Spectrogram, CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acc8e79-a4ea-489d-8dbb-7853dd5dc433",
   "metadata": {},
   "source": [
    "An alternative approach is to import the package and access the classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1d27fed-1d75-43fd-acd0-93053e1d7a4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Audio.from_file of <class 'opensoundscape.audio.Audio'>>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import opensoundscape as opso\n",
    "opso.Audio.from_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbf8bab-ef6e-4108-aa4a-be1609862027",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4432db08-f690-44cb-8a98-fa4b4c5b2780",
   "metadata": {
    "tags": []
   },
   "source": [
    "## WandB Integration\n",
    "\n",
    "Weights and Biases (WandB) is a great web-based tool for monitoring machine learning training and other processes. OpenSoundscape now natively supports logging to WandB during training and prediction with the `CNN` class. \n",
    "\n",
    "All you need to do is log in and initialize a wandb \"session\" - this will create a page on the WandB where any metrics and graphics are automatically logged. You can easily inspect samples from your dataset, see how metrics change over the course of training, and compare metrics across multiple training runs. It's also a great place to add notes about what makes each training run unique, and will keep track of hyperparameters used during CNN training.\n",
    "\n",
    "To use WandB, create an account and find your API key, which you will use to log in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98e15192-be54-49c4-a0dc-52cd2a26f379",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "# wandb.login(key='...') #put your api key here, find it at https://wandb.ai/settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07bc4b5-4760-4899-bd16-d7fd7f8db127",
   "metadata": {},
   "source": [
    "Now, create a new session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3534f333-744b-4ca3-9407-e8ee85376ec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3ebd879a8d94cee8e462187ed881902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01670067708333439, max=1.0)â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem at: /var/folders/d8/265wdp1n0bn_r85dh3pp95fh0000gq/T/ipykernel_37278/1733791050.py 1 <cell line: 1>\n"
     ]
    },
    {
     "ename": "UsageError",
     "evalue": "Error communicating with wandb process\nFor more info see: https://docs.wandb.ai/library/init#init-start-error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUsageError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/d8/265wdp1n0bn_r85dh3pp95fh0000gq/T/ipykernel_37278/1733791050.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m wandb_session = wandb.init(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mentity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'kitzeslab'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#a shared group on the wandb platform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"trying wandb in opensoundscape\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#a collection of runs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test internal logging'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#optionally, name this specific run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# add any extra hyperparameters or info for this run in the `config` dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/opso_dev/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m   1076\u001b[0m         \u001b[0mexcept_exit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_except_exit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1078\u001b[0;31m             \u001b[0mrun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1079\u001b[0m             \u001b[0mexcept_exit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_except_exit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/opso_dev/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mUsageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mrun_result\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrun_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrun_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresumed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUsageError\u001b[0m: Error communicating with wandb process\nFor more info see: https://docs.wandb.ai/library/init#init-start-error"
     ]
    }
   ],
   "source": [
    "wandb_session = wandb.init(\n",
    "    entity='kitzeslab', #a shared group on the wandb platform\n",
    "    project=\"trying wandb in opensoundscape\", #a collection of runs\n",
    "    name='test internal logging', #optionally, name this specific run\n",
    "    # add any extra hyperparameters or info for this run in the `config` dictionary\n",
    "    config=dict( \n",
    "        comment=\"Description: extra comment from training notebook\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c355e6d-ae5a-47a5-90a6-7a916661a746",
   "metadata": {},
   "source": [
    "We can see that WandB has created a website where we can see anything we log to this `wandb_session`. The .train() and .predict() methods of CNN in OpenSoundscape will log useful metrics and preprocessed samples if we pass the `wandb_session` to the `wandb_session` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772ac943-cc19-47b3-8c63-56c96b924fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(architecture='efficientnet_b4', classes=['bird'], sample_duration=1.0)\n",
    "samples = ['./resources/birds_10s.wav']\n",
    "score_dataframe = model.predict(samples,wandb_session=wandb_session)\n",
    "wandb.finish() #let wandb know your run has finished"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40fb688-4985-4a8c-979e-0d9f5ad75b00",
   "metadata": {},
   "source": [
    "We can go to the link above to see the results! \n",
    "(Hint: train() provides more interesting things to look at than predict())\n",
    "\n",
    "Some things logged by predict include \n",
    "- a random set of preprocessed samples that we can listen to and see\n",
    "- the top-scoring samples per class\n",
    "- progress through all prediction batches\n",
    "- whether the run is complete, failed, or still running\n",
    "\n",
    "The model.wandb_logging dictionary has some configurable parameteres for logging samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b118fbfd-63a2-4337-bf30-95fd903fdb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wandb_logging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92909538-7153-4743-9d8f-81e91dfe22e5",
   "metadata": {},
   "source": [
    "## EfficientNet architecture added\n",
    "We snuck an example into the previous cell :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3870ebf6-244b-43a9-ad9f-274024e4c452",
   "metadata": {},
   "source": [
    "## Changes to CNN.predict()\n",
    "again, we snuck an example in that last python cell - notice that model.predict() now just returns a single dataframe containing the CNN score outputs. We can still apply an activation layer if we want with the predict() function, but it doesn't return boolean 0/1 predictions. \n",
    "\n",
    "To generate 0/1 predictions from an array or dataframe of continuous scores, use the functions `predict_multi_target_labels` and `predict_single_target_labels`from the `metrics` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5c66d7-32f8-4ec0-883b-dc3296daa7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = opso.metrics.predict_multi_target_labels(score_dataframe,threshold=0)\n",
    "predictions.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7a6fd5-f099-4979-9314-44c90a6e30e0",
   "metadata": {},
   "source": [
    "Note that because CNN.predict() doesn't generate binary predictions, it also no longer accepts arguments for \"threshold\" and \"binary_preds\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58575c3-64c4-4a3c-8a12-dad81a2323c5",
   "metadata": {},
   "source": [
    "## Preference for 1 class for single-class models\n",
    "this is the third thing we snuck into the previous example: when training a CNN to recognize one thing, we recommend having just one class (rather than two classes `present` and `absent`). Either is mathematically valid, but having one output node makes more sense and will cause you less hastle in general. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4f2bf1-655a-45e7-a3a2-dee10d5a5dad",
   "metadata": {},
   "source": [
    "## Train on unsplit audio\n",
    "It works... try it!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097f4da3-bfa9-49b2-958a-bb961a2fd82c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Tracing and debugging preprocessing errors - coming soon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56b4b23-c493-4870-a248-cb41b608b4da",
   "metadata": {},
   "source": [
    "## GradCAM - coming soon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3a6238-f379-433c-a646-84623a7a8c95",
   "metadata": {
    "tags": []
   },
   "source": [
    "## new augmentations\n",
    "random gain and add noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "77c939bf-b718-4fe7-8624-20800ebc77b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function opensoundscape.preprocess.actions.audio_add_noise(audio, noise_dB=-30, signal_dB=0, color='white')>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opso.actions.audio_add_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "344f9ead-aa35-4c6c-bbe7-fc711c14640f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function opensoundscape.preprocess.actions.audio_random_gain(audio, dB_range=(-30, 0), clip_range=(-1, 1))>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opso.actions.audio_random_gain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4adefc-66a9-4e30-82b4-7b25ab565d3d",
   "metadata": {},
   "source": [
    "## VGGish\n",
    "VGGish is a pre-trained audio feature extractor. It's easy to use the pytorch model hub version in OpenSoundscape.\n",
    "\n",
    "(example)[https://github.com/kitzeslab/bioacoustics-cookbook/blob/main/vggish.ipynb] of how to use it with OpenSoundscape in bioacoustic cookbook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44092f3f-d3c6-4de3-92cd-a9401bd73a80",
   "metadata": {},
   "source": [
    "## M1 chip / Apple Silicon GPU error workaround\n",
    "falls back to CPU if torch's logit fails with Not Implemented Error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a251b9-7604-4975-a0ac-6346022acab9",
   "metadata": {},
   "source": [
    "# Audio Objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b933c678-a6b8-498c-888a-00e78df1d22d",
   "metadata": {},
   "source": [
    "## Robust metadata\n",
    "Audio.save now saves metadata dictionaries in JSON (in the \"comment\" field of standard metadata), allowing us to keep track of arbitrary fields and modify+recover the \"recording_start_time\" (datetime.datetime) field. \n",
    "\n",
    "Note that if you add more than 30-50 metadata fields it will run out of space and fail silently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "880c3519-cc82-4082-a1b1-657ea0723edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'samplerate': 32000,\n",
       " 'format': 'WAV',\n",
       " 'frames': 324263,\n",
       " 'sections': 1,\n",
       " 'subtype': 'PCM_16',\n",
       " 'channels': 1,\n",
       " 'duration': 10.13321875}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=Audio.from_file('./resources/birds_10s.wav')\n",
    "a.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b2c5d66a-4468-442d-9112-d0dd6f2d17fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'samplerate': 32000,\n",
       " 'format': 'WAV',\n",
       " 'frames': 324263,\n",
       " 'sections': 1,\n",
       " 'subtype': 'PCM_16',\n",
       " 'channels': 1,\n",
       " 'duration': 10.13321875,\n",
       " 'special note': 'does not contain IBWO',\n",
       " 'opso_metadata_version': 'v0.1',\n",
       " 'opensoundscape_version': '0.7.1'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.metadata['special note']=\"does not contain IBWO\"\n",
    "a.save('./resources/saved_file.wav')\n",
    "Audio.from_file('./resources/saved_file.wav').metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f9bc50-5e6f-41dc-b1a4-31f644846fdf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Audio class additions: \n",
    "- .silence()\n",
    "- .noise()\n",
    "- .normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "093af6c8-a29d-445c-884b-fd5fce3cd069",
   "metadata": {},
   "outputs": [],
   "source": [
    "silent = Audio.silence(duration=3,sample_rate=32000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "48153b7d-8567-4ed7-bf1a-eaac9ee2c9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pink = Audio.noise(duration=3,sample_rate=32000,dBFS=-5,color='pink')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a986597c-a607-4d60-a1e7-d6ff3bef9318",
   "metadata": {},
   "source": [
    "## _properties_\n",
    "New properties:\n",
    "- rms\n",
    "- dBFS\n",
    "\n",
    "Converted from functions to properties:\n",
    "- duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "14714b4d-1680-428c-9734-a2d4bad1d4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/SML161/opensoundscape/opensoundscape/audio.py:817: RuntimeWarning: divide by zero encountered in log10\n",
      "  return 20 * np.log10(self.rms * np.sqrt(2))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-inf"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "silent.dBFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e06be6d3-2440-4354-b083-1628d84081b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "silent.rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7f4423d6-be5e-4e6a-8ef1-27470b79aa4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "silent.duration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700c688e-c6f4-4818-b1b9-ad92a41b1c4e",
   "metadata": {},
   "source": [
    "## normalize method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "83de29ca-ac5e-42a5-825a-6685116cdcdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Audio(samples=(96000,), sample_rate=32000)>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pink.normalize(peak_dBFS=-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea2f207-1d29-4faf-900a-f5b68c18850c",
   "metadata": {},
   "source": [
    "# Spectrogram objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54806688-60a3-4425-88fc-9fe6153f7d82",
   "metadata": {},
   "source": [
    "## properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6728c284-7838-4725-8ba8-a1a397241f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.127999999999998\n"
     ]
    }
   ],
   "source": [
    "s=Spectrogram.from_audio(a)\n",
    "print(s.duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "daf2b601-c21f-4c2b-8aee-341eb767b9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0000e+00 8.0000e-03 1.6000e-02 ... 1.0096e+01 1.0104e+01 1.0112e+01]\n"
     ]
    }
   ],
   "source": [
    "print(s.window_start_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e70605-0417-478d-9871-df8f8d9cdf8f",
   "metadata": {},
   "source": [
    "# [Discussions](https://github.com/kitzeslab/opensoundscape/discussions) page!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opso_dev",
   "language": "python",
   "name": "opso_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
